{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe37be29-ba22-4e35-993e-12dbbe4a75a4",
   "metadata": {},
   "source": [
    "Here one can find how to use available data and model classes to do time-series prediction.\n",
    "Currently supported models:\n",
    "1. **Temporal - in, temporal - out**. Given N past temporal observations, predict M  temporal steps into the future.\n",
    "2. **STFT - in, STFT - out**. Given N past observations of STFT features, predict M steps into the future for STFT features.\n",
    "3. (Experimental) **STFT - in, temporal - out**. Given N past observations of STFT features, predict M temporal steps into the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb501d80-6c44-4388-8004-a59597b8886c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.testing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# import necessary things from our custom library\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlaser_jitter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimeSeries, TimeSeriesSTFT, TimeSeriesInSTFTOutTime\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlaser_jitter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_basic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTMForecaster\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlaser_jitter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (RNNTemporal, RNNSTFT, RNNSTFT_real_imag, RNNSTFT_ensemble,\n\u001b[1;32m     22\u001b[0m                                 RNNSTFTInTimeOut)\n",
      "File \u001b[0;32m~/laser-jitter/laser_jitter/data.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mData classes for time series analysis and functions for creating dataloaders\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msignal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stft, istft\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, MinMaxScaler\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/scipy/signal/__init__.py:324\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_upfirdn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m upfirdn\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_spline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     cspline2d,\n\u001b[1;32m    318\u001b[0m     qspline2d,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    321\u001b[0m     symiirorder2,\n\u001b[1;32m    322\u001b[0m )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bsplines\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_filter_design\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fir_filter_design\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/scipy/signal/_bsplines.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m comb\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m float_factorial\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterpolate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BSpline\n\u001b[1;32m     14\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspline_filter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbspline\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgauss_spline\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcubic\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquadratic\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcspline1d\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqspline1d\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcspline1d_eval\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqspline1d_eval\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspline_filter\u001b[39m(Iin, lmbda\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5.0\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/scipy/interpolate/__init__.py:167\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m========================================\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mInterpolation (:mod:`scipy.interpolate`)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m(should not be used in new code).\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_interpolate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fitpack_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# New interface to fitpack library:\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/scipy/interpolate/_interpolate.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspec\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m comb\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _fitpack_py\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dfitpack\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_polyint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _Interpolator1D\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/scipy/interpolate/_fitpack_py.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fitpack_impl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bisplrep, bisplev, dblint  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _fitpack_impl \u001b[38;5;28;01mas\u001b[39;00m _impl\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bsplines\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BSpline\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplprep\u001b[39m(x, w\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, u\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ub\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ue\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, task\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, t\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m             full_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, nest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, per\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, quiet\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    Find the B-spline representation of an N-D curve.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m \n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/scipy/interpolate/_bsplines.py:9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultiarray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normalize_axis_index\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (get_lapack_funcs, LinAlgError,\n\u001b[1;32m      7\u001b[0m                           cholesky_banded, cho_solve_banded,\n\u001b[1;32m      8\u001b[0m                           solve, solve_banded)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m minimize_scalar\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _bspl\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _fitpack_impl\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/scipy/optimize/__init__.py:410\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m=====================================================\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mOptimization and root finding (:mod:`scipy.optimize`)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    406\u001b[0m \n\u001b[1;32m    407\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_optimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m--> 410\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_minimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_root\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_root_scalar\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/scipy/optimize/_minimize.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_trustregion_krylov\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _minimize_trust_krylov\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_trustregion_exact\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _minimize_trustregion_exact\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_trustregion_constr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _minimize_trustregion_constr\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# constrained minimization\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lbfgsb_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _minimize_lbfgsb\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/scipy/optimize/_trustregion_constr/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"This module contains the equality constrained SQP solver.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mminimize_trustregion_constr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _minimize_trustregion_constr\n\u001b[1;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_minimize_trustregion_constr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/scipy/optimize/_trustregion_constr/minimize_trustregion_constr.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearOperator\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_differentiable_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorFunction\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_constraints\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m     NonlinearConstraint, LinearConstraint, PreparedConstraint, strict_bounds)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_hessian_update_strategy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BFGS\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_optimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OptimizeResult\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/scipy/optimize/_constraints.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_optimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OptimizeWarning\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn, catch_warnings, simplefilter\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m suppress_warnings\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arr_to_scalar\u001b[39m(x):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# If x is a numpy array, return x.item().  This will\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# fail if the array has more than one element.\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.testing'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "\n",
    "rcParams['figure.figsize'] = (8,4)\n",
    "rcParams['font.size'] = 14\n",
    "rcParams['lines.linewidth'] = 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import necessary things from our custom library\n",
    "from laser_jitter.data import TimeSeries, TimeSeriesSTFT, TimeSeriesInSTFTOutTime\n",
    "from laser_jitter.model_basic import LSTMForecaster\n",
    "from laser_jitter.model import (RNNTemporal, RNNSTFT, RNNSTFT_real_imag, RNNSTFT_ensemble,\n",
    "                                RNNSTFTInTimeOut)\n",
    "from laser_jitter.utils import read_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e77b2b9-65df-469f-abaf-7f6215ef1bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"/home/wi73yus/focus_deviation/data/cryo07_decFULL.csv\", header=None)\n",
    "data = data.rename({0: 'real_time', 1:'focus_location'}, axis=1)\n",
    "data['time_idx'] = np.arange(len(data['real_time']))\n",
    "\n",
    "ts_data = np.array(data['focus_location'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68057eae-a913-421a-ae64-0b4ebf8fa611",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Temporal model\n",
    "<img src=\"figures/problem_setting_forecast.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "Using some `training horizon` (N observations from the past), predict `prediction_horizon` (M future observations). Smooth true data beforehand to simplify the pattern to be learned by NN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dc2809-8195-4072-ab91-c51b3f857e32",
   "metadata": {},
   "source": [
    "### Data class usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f3322d-5bec-4d8c-9666-82f429c50e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# introduce smoothing parameters for the series\n",
    "N = 5\n",
    "smooth_params = {\n",
    "    'kernel': np.ones(N)/N,\n",
    "}\n",
    "scaling = 'standard' # choose scaling\n",
    "\n",
    "# class automatically smoothes data, splits it in train/test and scales to be in \n",
    "# a good range as input for NN\n",
    "series_class = TimeSeries(ts_data, smooth_params=smooth_params, train_size=0.8,\n",
    "                          scaling=scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f955a-4d87-4192-83f4-83ae5d05f15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check series and its smoothed version\n",
    "series = series_class.series\n",
    "series_smooth = series_class.series_smooth\n",
    "\n",
    "start, end = 100, 300\n",
    "plt.figure()\n",
    "plt.plot(series[start:end], label='original')\n",
    "plt.plot(series_smooth[start:end], label='smooth')\n",
    "plt.ticklabel_format(axis='y', style='sci', scilimits=(-3,-3))\n",
    "plt.xlabel('Time [ms]')\n",
    "plt.ylabel('Divergence [$\\mu$rad]')\n",
    "plt.title('Original and smoothed series')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Check scaled series\n",
    "train = series_class.train\n",
    "test = series_class.test\n",
    "\n",
    "start, end = 100, 300\n",
    "plt.figure()\n",
    "plt.plot(train[start:end], label='scaled')\n",
    "plt.xlabel('Time [ms]')\n",
    "plt.ylabel('Divergence [$\\mu$rad]')\n",
    "plt.title('Scaled series')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c3bad7-0545-4b59-84d8-c0e9903aca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One can transform data:\n",
    "# 1) original series -> suitable as input to NN\n",
    "# 2) NN prediction -> original scale\n",
    "\n",
    "sample = ts_data[:200]\n",
    "sample_nn, sample_smooth_nn = series_class.transform_series(sample)\n",
    "sample_recovered = series_class.inverse_transform_series(sample_smooth_nn)\n",
    "\n",
    "# Due to smoothing which cuts the boundary regions of time-series, the original\n",
    "# and back-transformed series look shifted\n",
    "plt.figure()\n",
    "plt.plot(sample, label='original')\n",
    "plt.plot(sample_recovered, label='back-tranformed')\n",
    "plt.ticklabel_format(axis='y', style='sci', scilimits=(-3,-3))\n",
    "plt.xlabel('Time [ms]')\n",
    "plt.ylabel('Divergence [$\\mu$rad]')\n",
    "plt.title('Original and back-transformed series')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6506d7-b131-49d1-ba25-97ad26d61154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders for NN (this is what needed for training and accuracy evaluation)\n",
    "\n",
    "training_window = 300\n",
    "prediction_window = 100\n",
    "sequence_params = {\n",
    "    'training_window': training_window,\n",
    "    'prediction_window': prediction_window,\n",
    "    'step': 1\n",
    "}\n",
    "\n",
    "dataloader_params = {\n",
    "    'batch_size': 128,\n",
    "    'drop_last': False,\n",
    "}\n",
    "\n",
    "loaders = series_class.create_dataloaders(series_class.train,\n",
    "                                          series_class.test,\n",
    "                                          sequence_params, dataloader_params)\n",
    "trainloader, testloader = loaders\n",
    "\n",
    "loaders = series_class.create_dataloaders(series_class.train_smooth,\n",
    "                                          series_class.test_smooth,\n",
    "                                          sequence_params, dataloader_params)\n",
    "trainloader_smooth, testloader_smooth = loaders\n",
    "\n",
    "print(f'Trainloader length: {len(trainloader_smooth)}')\n",
    "print(f'Testloader length:  {len(testloader_smooth)}')\n",
    "\n",
    "for x,y in trainloader_smooth:\n",
    "    print(f'Input shape:  {x.shape}')\n",
    "    print(f'Target shape: {y.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bbd86f-03df-4e35-8e96-c0c84aa69705",
   "metadata": {},
   "source": [
    "### Model class usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1adff0-6948-4874-9ae5-ec0a973d57c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the model training and inference we need dataloaders provided by the \n",
    "# appropriate data class\n",
    "n_features = 1\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if use_cuda else 'cpu'\n",
    "\n",
    "n_hidden_lstm = 64\n",
    "model_params = {\n",
    "    'n_features': n_features,\n",
    "    'n_hidden_lstm': n_hidden_lstm,\n",
    "    'n_hidden_fc': 1000,\n",
    "    'n_outputs': prediction_window*n_features,\n",
    "    'n_out_features': 1,\n",
    "    'sequence_len': training_window,\n",
    "    'n_lstm_layers': 2,\n",
    "    'n_deep_layers': 1,\n",
    "    'dropout': 0.2,\n",
    "    'use_cuda': use_cuda\n",
    "}\n",
    "save_folder = f'models/rnn_temporal_tw_{training_window}_pw_{prediction_window}_hidlstm_{n_hidden_lstm}/'\n",
    "load_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a9846f-3b83-4b0a-8ab8-2c4147b510fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High-level model can be created by passing appropriate model_params without \n",
    "# model itself or with actual model\n",
    "\n",
    "# Without model\n",
    "model_high_level = RNNTemporal(model_params, None, save_folder)\n",
    "\n",
    "# With model\n",
    "model = LSTMForecaster(**model_params).to(device)\n",
    "model_high_level = RNNTemporal(model_params, model, save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b544dc23-f4ca-4f37-88bd-99860c7f935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whenever high-level model is created, its parameters are saved to .yml file\n",
    "# to its save directory for tractability. Be careful to use the same save folder\n",
    "# because model_params.yml would be overwritten\n",
    "yaml_file = glob.glob(f'{save_folder}*.yml')[0]\n",
    "print(yaml_file)\n",
    "\n",
    "model_params = read_yaml(yaml_file)\n",
    "print(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b54d3b-3535-4d40-bb9b-65e063383a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each high-level model has following methods: train, predict, inference_on_dataloader,\n",
    "# predict_on_series\n",
    "\n",
    "# Training model uses dataloaders and saves `best model` to its save folder from which it\n",
    "# could be later loaded with model.load_best_model()\n",
    "\n",
    "# Define training parameters\n",
    "lr = 1e-4\n",
    "n_epochs = 20\n",
    "\n",
    "# Initialize the loss function and optimizer\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.AdamW(model_high_level.model.parameters(), lr=lr)\n",
    "\n",
    "# train the model\n",
    "losses = model_high_level.train(trainloader_smooth, testloader_smooth,\n",
    "                                criterion, optimizer, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc940a55-d5bb-4fc2-908a-e28fad95e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the training curves, star corresponds to the best performance on the train set\n",
    "plt.figure(figsize=(16,6))\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.plot(losses[i])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    if i == 1:\n",
    "        idx = np.argmin(losses[1])\n",
    "        plt.plot(idx, losses[1][idx], '*', color='red', ms=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae97b03-79b7-4b6f-8aab-5d5b9c5e5ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the model in high-level model class to its best variant\n",
    "model_high_level.load_best_model() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af61a85d-e7d4-478f-9a42-43a9774acdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference on testloaders\n",
    "data, metrics = model_high_level.inference_on_dataloader(testloader, series_class,\n",
    "                                                         testloader_smooth)\n",
    "predictions, actuals, actuals_smooth = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c15fd22-156f-474a-b69d-9a4c1d98d300",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shapes: {predictions.shape}, {actuals.shape}')\n",
    "print(f'MAE: {metrics[0]}')\n",
    "print(f'RMS: {metrics[1]}')\n",
    "\n",
    "# an example of prediction\n",
    "idx = 2000\n",
    "plt.figure()\n",
    "plt.plot(actuals[idx], label='true')\n",
    "plt.plot(actuals_smooth[idx], label='true smooth')\n",
    "plt.plot(predictions[idx], label='prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b131a83-809c-4ef8-ba2a-7fdfe1f6522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare inference time for model on CPU/GPU\n",
    "# Step 1: create models on CPU/GPU\n",
    "models = []\n",
    "for use_cuda in [False, True]:\n",
    "    device = 'cuda' if use_cuda else 'cpu'\n",
    "    \n",
    "    model_params_local = model_params.copy()\n",
    "    model_params_local['use_cuda'] = use_cuda\n",
    "\n",
    "    model = None #LSTMForecaster(**model_params).to(device)\n",
    "    model_high_level = RNNTemporal(model_params_local, model, save_folder, load_model=True)\n",
    "    models.append(model_high_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b663ccc4-7ef9-416e-aaa2-7b5fc6823770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: choose time-series slice\n",
    "t0 = 17500\n",
    "N = 5\n",
    "\n",
    "past_start, past_end = t0-N//2, t0+training_window+N//2 \n",
    "future_start, future_end = t0+training_window+N//2, t0+training_window+N//2+prediction_window\n",
    "series_past = series_class.series[past_start:past_end].squeeze()\n",
    "series_future = series_class.series[future_start:future_end].squeeze()\n",
    "\n",
    "predictions = []\n",
    "devices = ['cpu', 'cuda']\n",
    "for i,device in enumerate(devices):\n",
    "    models[i].model.eval()\n",
    "    t_start = time.time()\n",
    "    prediction = models[i].predict_on_series(series_past, series_class, device=device)\n",
    "    t_pred = time.time() - t_start\n",
    "    predictions.append(prediction)\n",
    "    print('Prediction time ({}): {:3.1f} ms'.format(device, t_pred*1e3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d93ef79-c5f9-497c-a73c-fd6ee0b4dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: observe the results\n",
    "err = np.abs(series_future - prediction)\n",
    "rms_ini = np.sqrt(np.mean(series_future**2))\n",
    "rms = np.sqrt(np.mean(err**2))\n",
    "print(f'rms (initial): {rms_ini}')\n",
    "print(f'rms          : {rms}')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(prediction_window)+2, series_future, label='true')\n",
    "for i in range(2):\n",
    "    plt.plot(predictions[i], label=f'prediction ({devices[i]})')\n",
    "plt.xlabel('Time [ms]')\n",
    "plt.ylabel('Divergence [$\\mu$rad]')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.abs(series_future - prediction))\n",
    "plt.xlabel('Time [ms]')\n",
    "plt.ylabel('|true - prediction|')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ce5a87-5d96-4824-8631-637adb678426",
   "metadata": {},
   "source": [
    "## STFT models\n",
    "\n",
    "![](figures/stft_model.png)\n",
    "\n",
    "The idea is to convert temporal signal with STFT to spectrogram with time-frequency information, use `training_window` past time steps to predict `prediction_window` future time steps for real and imaginary part of dominant frequency bands (the amplitude of which over period of time is large enough compared to the mean value). Since the number of input features is larger than in temporal case (this is no longer univariate time-series forecasting), we have a choice how many models we would use for the forecasting of all features. Available choices (all models use the same data class):\n",
    "1. One model for all. Predicts both real and imag part of dominant frequency bands.\n",
    "2. One model for real part of all frequency bands, one model for imag part.\n",
    "3. Separate model for each frequency band's real/imag part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258a1428-14aa-4a02-b7f6-ae32694d0e60",
   "metadata": {},
   "source": [
    "### Data class usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2b643a-a1e9-4d36-a367-03d40dbdc442",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 500\n",
    "stft_params = {\n",
    "    'nperseg': window_length,\n",
    "    'fs': 1e3,\n",
    "    'boundary': None,\n",
    "    'noverlap': window_length-1,\n",
    "    'padded': False,\n",
    "    'window': 'tukey'\n",
    "}\n",
    "\n",
    "# parameters to filter out 'dominant' frequency bands from the spectrogram,\n",
    "# 'thresh_weight' is weight multiplied by the mean amplitude of all frequency bands\n",
    "# 'freq_low' is low frequency boundary from which we conssider frequency bands\n",
    "# for prediction\n",
    "filter_params = {\n",
    "    'thresh_weight': 1,\n",
    "    'freq_low': 0\n",
    "}\n",
    "scaling = 'standard'\n",
    "\n",
    "# N = 5\n",
    "# smooth_params = {\n",
    "#     'kernel': np.ones(N)/N,\n",
    "# }\n",
    "smooth_params = None\n",
    "\n",
    "# This data class automatically splits data to train/test, calculates stft of it,\n",
    "# filters out not dominant frequeny bands and applies scaling. Optionally one can\n",
    "# apply smoothing beforehand to the time-series\n",
    "series_class = TimeSeriesSTFT(ts_data, stft_params, train_size=0.8,\n",
    "                              filter_params=filter_params, scaling=scaling,\n",
    "                              smooth_params=smooth_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663f128d-e243-43d4-98ad-0ed98c761d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the spectrogram and its filtered version (some of the bands are \n",
    "# zeroed out)\n",
    "t, freq, spectrum = series_class.t, series_class.freq, series_class.train_stft\n",
    "spectrum_filt = series_class.train_stft_filt\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(121)\n",
    "plt.pcolormesh(t, freq, np.abs(spectrum), cmap='jet')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.colorbar()\n",
    "plt.ylim([0,150])\n",
    "plt.title('STFT')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.pcolormesh(t, freq, np.abs(spectrum_filt), cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.ylim([0,150])\n",
    "plt.title('STFT (filtered)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965fb087-0ebc-4c8d-912f-4ea59aa96836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the variation of amplitude for some frequency bands\n",
    "idxs = [10, 20]\n",
    "n = len(idxs)\n",
    "plt.figure(figsize=(n*6,4), layout='constrained')\n",
    "for i in range(n):\n",
    "    plt.subplot(1,n,i+1)\n",
    "    plt.plot(t, np.abs(spectrum[idxs[i]]))\n",
    "    plt.ticklabel_format(axis='y', style='sci', scilimits=(-4,-4))\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title('$\\\\omega = {:2.0f}$ Hz'.format(freq[idxs[i]]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f15d3b-8eb1-4044-817c-8e4de5255d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original and back-transformed signal\n",
    "start, end = 500, 1100\n",
    "sample = ts_data[start:end]\n",
    "sample_transformed = series_class.transform_series(sample)\n",
    "sample_recovered = series_class.inverse_transform_series(sample_transformed)\n",
    "print('Shapes: ', sample.shape, sample_transformed.shape, sample_recovered.shape)\n",
    "\n",
    "# Since we zero out some of the frequency bands, we do not reconstruct the original \n",
    "# signal fully, the problems are especially noticeable for boundary region\n",
    "plt.figure()\n",
    "plt.plot(sample, label='original')\n",
    "plt.plot(sample_recovered, label='back-tranformed')\n",
    "plt.ticklabel_format(axis='y', style='sci', scilimits=(-3,-3))\n",
    "plt.ylim([-10e-3,10e-3])\n",
    "plt.xlabel('Time [ms]')\n",
    "plt.ylabel('Divergence [$\\mu$rad]')\n",
    "plt.title('Original and back-transformed series')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e2c276-616e-4b1b-96ea-a194a3d49440",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_window = 400\n",
    "prediction_window = 200\n",
    "forecast_window = 100\n",
    "sequence_params = {\n",
    "    'training_window': training_window,\n",
    "    'prediction_window': prediction_window,\n",
    "    'step': 1\n",
    "}\n",
    "\n",
    "dataloader_params = {\n",
    "    'batch_size': 64,\n",
    "    'drop_last': False,\n",
    "}\n",
    "\n",
    "\n",
    "loaders = series_class.create_dataloaders(series_class.train_real, series_class.train_imag,\n",
    "                                          series_class.test_real, series_class.test_imag,\n",
    "                                          sequence_params, dataloader_params)\n",
    "trainloader, testloader = loaders\n",
    "\n",
    "print(f'Trainloader length: {len(trainloader)}')\n",
    "print(f'Testloader length:  {len(testloader)}')\n",
    "\n",
    "for x, y in trainloader:\n",
    "    print(f'Input shape:  {x.shape}')\n",
    "    print(f'Target shape: {y.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b3b792-2723-4cdb-9104-115f78e178e3",
   "metadata": {},
   "source": [
    "### Single model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f330c3-73ed-46cb-926f-175c0715047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(series_class.freq_filt)*2\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if use_cuda else 'cpu'\n",
    "print(device)\n",
    "\n",
    "n_hidden_lstm = 64\n",
    "n_hidden_fc = 1000\n",
    "model_params = {\n",
    "    'n_features': n_features,\n",
    "    'n_hidden_lstm': n_hidden_lstm,\n",
    "    'n_hidden_fc': n_hidden_fc,\n",
    "    'n_outputs': prediction_window*n_features,\n",
    "    'n_out_features': n_features,\n",
    "    'sequence_len': training_window,\n",
    "    'n_lstm_layers': 2,\n",
    "    'n_deep_layers': 1,\n",
    "    'dropout': 0.2,\n",
    "    'use_cuda': use_cuda\n",
    "}\n",
    "save_folder = f'models/rnn_stft_tw_{training_window}_pw_{prediction_window}_hidlstm_{n_hidden_lstm}_hidfc_{n_hidden_fc}/'\n",
    "load_model = False\n",
    "# load_model = True\n",
    "\n",
    "model = LSTMForecaster(**model_params).to(device) if not load_model else None\n",
    "model_high_level = RNNSTFT(model_params, model, save_folder, load_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f538438-f12a-4889-a987-7dcea6203783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "lr = 1e-4\n",
    "n_epochs = 15\n",
    "\n",
    "# Initialize the loss function and optimizer\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.AdamW(model_high_level.model.parameters(), lr=lr)\n",
    "\n",
    "# train the model\n",
    "losses = model_high_level.train(trainloader, testloader,\n",
    "                                criterion, optimizer, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6774982f-fda0-47d5-98a3-463e6645f1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the training curves, star corresponds to the best performance on the train set\n",
    "plt.figure(figsize=(16,6))\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.plot(losses[i])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    if i == 1:\n",
    "        idx = np.argmin(losses[1])\n",
    "        plt.plot(idx, losses[1][idx], '*', color='red', ms=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174d1c6b-b442-4829-b7e7-9d8878fb9a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the model in high-level model class to its best variant\n",
    "model_high_level.load_best_model() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4159345b-076c-43df-ad95-3c214350466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference on test series\n",
    "t0 = 16000\n",
    "train = ts_data[:t0]\n",
    "test = ts_data[t0:]\n",
    "\n",
    "data, metrics = model_high_level.inference_on_dataloader(test, series_class,\n",
    "                                                         sequence_params,\n",
    "                                                         dataloader_params,\n",
    "                                                         forecast_window)\n",
    "predictions, actuals = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b98c4ca-ab59-463d-b15c-dbf9971aa4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shapes: {predictions.shape}, {actuals.shape}')\n",
    "print(f'MAE: {metrics[0]}')\n",
    "print(f'RMS: {metrics[1]}')\n",
    "\n",
    "# an example of prediction\n",
    "idx = 2000\n",
    "plt.figure()\n",
    "plt.plot(actuals[idx], label='true')\n",
    "plt.plot(predictions[idx], label='prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53c7f1a-ac5b-4242-8a77-db8016b84e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare inference time for model on CPU/GPU\n",
    "# Step 1: create models on CPU/GPU\n",
    "models = []\n",
    "for use_cuda in [False, True]:\n",
    "    device = 'cuda' if use_cuda else 'cpu'\n",
    "    \n",
    "    model_params_local = model_params.copy()\n",
    "    model_params_local['use_cuda'] = use_cuda\n",
    "\n",
    "    model = None #LSTMForecaster(**model_params).to(device)\n",
    "    model_high_level = RNNSTFT(model_params_local, model, save_folder, load_model=True)\n",
    "    models.append(model_high_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d99fdd5-4f2e-4caa-b87d-6490c9741644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: choose time-series slice\n",
    "t0 = 17500\n",
    "window_len = stft_params['noverlap']\n",
    "\n",
    "past_start, past_end = t0-window_len, t0+training_window \n",
    "future_start, future_end = t0+training_window, t0+training_window+forecast_window\n",
    "series_past = series_class.series[past_start:past_end].squeeze()\n",
    "series_future = series_class.series[future_start:future_end].squeeze()\n",
    "\n",
    "predictions = []\n",
    "devices = ['cpu', 'cuda']\n",
    "for i,device in enumerate(devices):\n",
    "    models[i].model.eval()\n",
    "    t_start = time.time()\n",
    "    prediction = models[i].predict_on_series(series_past, series_class, device=device)\n",
    "    prediction = prediction[-prediction_window:-prediction_window+forecast_window]\n",
    "    t_pred = time.time() - t_start\n",
    "    predictions.append(prediction)\n",
    "    print('Prediction time ({}): {:3.1f} ms'.format(device, t_pred*1e3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb50b62b-3fb0-4fd7-9163-63482c2ba00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: observe the results\n",
    "err = np.abs(series_future - prediction)\n",
    "rms_ini = np.sqrt(np.mean(series_future**2))\n",
    "rms = np.sqrt(np.mean(err**2))\n",
    "print(f'rms (initial): {rms_ini}')\n",
    "print(f'rms          : {rms}')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(forecast_window), series_future, label='true')\n",
    "for i in range(2):\n",
    "    plt.plot(predictions[i], label=f'prediction ({devices[i]})')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.abs(series_future - prediction))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88a0ef0-305a-4325-8ad2-defc2047e007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the prediction in stft domain\n",
    "t0 = 1000\n",
    "start_past, end_past = t0, t0+training_window\n",
    "start_future, end_future = t0+training_window, t0+training_window+prediction_window\n",
    "window = stft_params['noverlap']\n",
    "series = series_class.test[start_past-window:end_future]\n",
    "series_in = series_class.test[start_past-window:end_past]\n",
    "\n",
    "freq, t, series_stft = series_class.calculate_stft(series)\n",
    "stft_in = series_class.transform_series(series)\n",
    "n_bands = stft_in.shape[1] // 2\n",
    "\n",
    "x = torch.Tensor(stft_in[:training_window])[None,:].to(device)\n",
    "prediction = model_high_level.predict(x).cpu().numpy().squeeze()\n",
    "\n",
    "real, imag = stft_in[:,:n_bands], stft_in[:,n_bands:]\n",
    "amplitudes = np.abs(real + 1j*imag)\n",
    "\n",
    "real_pred, imag_pred = prediction[:,:n_bands], prediction[:,n_bands:]\n",
    "amplitudes_pred = np.abs(real_pred + 1j*imag_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f40eb-665a-4789-b4b0-726862cc75db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.pcolormesh(t, freq, np.abs(series_stft), cmap='jet')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.colorbar()\n",
    "plt.ylim([0,150])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11168a1e-b8f9-43e7-87b4-4e8db86fd0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20), layout='constrained')\n",
    "for i in range(min([n_bands, 50])):\n",
    "    plt.subplot(10,5,i+1)\n",
    "    plt.plot(amplitudes[:,i], label='true')\n",
    "    plt.plot(training_window+np.arange(prediction_window), \n",
    "             amplitudes_pred[:,i], label='forecast')\n",
    "    plt.title('{:2.0f} Hz'.format(series_class.freq_filt[i]))\n",
    "    if i == 0:\n",
    "        plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dbd352-657b-42c6-892c-b4db75f496a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Two models (real/imag)\n",
    "For other model classes the usage is the same (same dataloaders used for train and same methods). One just needs to specify needed model class and correct number of input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7c8ca0-22cd-4792-aec3-6cb4d1adbbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice that the number of features is twice smaller than in the previous case\n",
    "n_features = len(series_class.freq_filt)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if use_cuda else 'cpu'\n",
    "print(device)\n",
    "\n",
    "n_hidden_lstm = 64\n",
    "n_hidden_fc = 1000\n",
    "model_params = {\n",
    "    'n_features': n_features,\n",
    "    'n_hidden_lstm': n_hidden_lstm,\n",
    "    'n_hidden_fc': n_hidden_fc,\n",
    "    'n_outputs': prediction_window*n_features,\n",
    "    'n_out_features': n_features,\n",
    "    'sequence_len': training_window,\n",
    "    'n_lstm_layers': 2,\n",
    "    'n_deep_layers': 1,\n",
    "    'dropout': 0.2,\n",
    "    'use_cuda': use_cuda\n",
    "}\n",
    "save_folder = f'models/rnn_stft_tw_{training_window}_pw_{prediction_window}_hidlstm_{n_hidden_lstm}_hidfc_{n_hidden_fc}/'\n",
    "load_model = False\n",
    "# load_model = True\n",
    "\n",
    "model = None\n",
    "model_high_level = RNNSTFT_real_imag(model_params, model, save_folder, load_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10c0ea0-ed31-4106-a5ba-166b10491b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "lr = 1e-4\n",
    "n_epochs = 15\n",
    "\n",
    "# Initialize the loss function and optimizer\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizers = [torch.optim.AdamW(model_high_level.model[i].parameters(), lr=lr) for i in range(2)]\n",
    "\n",
    "# train the model\n",
    "losses = model_high_level.train(trainloader, testloader,\n",
    "                                criterion, optimizers, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803e1a89-4646-4822-b204-1c05a00a17f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.plot(losses[i], label=['real', 'imag'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    if i == 1:\n",
    "        loss0 = np.array(losses[1])[:,0]\n",
    "        loss1 = np.array(losses[1])[:,1]\n",
    "        idx0 = np.argmin(loss0)\n",
    "        idx1 = np.argmin(loss1)\n",
    "        plt.plot(idx0, loss0[idx0], '*', color='blue', ms=20)\n",
    "        plt.plot(idx1, loss1[idx1], '*', color='orange', ms=20)\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15904b47-82eb-4c18-8eb0-7b2e8958fa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = 16000\n",
    "train = ts_data[:t0]\n",
    "test = ts_data[t0:]\n",
    "\n",
    "data, metrics = model_high_level.inference_on_dataloader(test, series_class,\n",
    "                                                         sequence_params,\n",
    "                                                         dataloader_params,\n",
    "                                                         forecast_window)\n",
    "predictions, actuals = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb03dc51-da26-4532-aa20-7861c896b8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shapes: {predictions.shape}, {actuals.shape}')\n",
    "print(f'MAE: {metrics[0]}')\n",
    "print(f'RMS: {metrics[1]}')\n",
    "\n",
    "# an example of prediction\n",
    "idx = 2000\n",
    "plt.figure()\n",
    "plt.plot(actuals[idx], label='true')\n",
    "plt.plot(predictions[idx], label='prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b200f2-e825-401f-9c9e-0189cfcc68d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare inference time for model on CPU/GPU\n",
    "# Step 1: create models on CPU/GPU\n",
    "models = []\n",
    "for use_cuda in [False, True]:\n",
    "    device = 'cuda' if use_cuda else 'cpu'\n",
    "    \n",
    "    model_params_local = model_params.copy()\n",
    "    model_params_local['use_cuda'] = use_cuda\n",
    "\n",
    "    model = None #LSTMForecaster(**model_params).to(device)\n",
    "    model_high_level = RNNSTFT_real_imag(model_params_local, model,\n",
    "                                         save_folder, load_model=True)\n",
    "    models.append(model_high_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d322175-8ecb-431c-811f-1b33a47e9b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: choose time-series slice\n",
    "t0 = 17500\n",
    "window_len = stft_params['noverlap']\n",
    "\n",
    "past_start, past_end = t0-window_len, t0+training_window \n",
    "future_start, future_end = t0+training_window, t0+training_window+forecast_window\n",
    "series_past = series_class.series[past_start:past_end].squeeze()\n",
    "series_future = series_class.series[future_start:future_end].squeeze()\n",
    "\n",
    "predictions = []\n",
    "devices = ['cpu', 'cuda']\n",
    "for i,device in enumerate(devices):\n",
    "    for j in range(models[i].n_models):\n",
    "        models[i].model[j].eval()\n",
    "    t_start = time.time()\n",
    "    prediction = models[i].predict_on_series(series_past, series_class, device=device)\n",
    "    prediction = prediction[-prediction_window:-prediction_window+forecast_window]\n",
    "    t_pred = time.time() - t_start\n",
    "    predictions.append(prediction)\n",
    "    print('Prediction time ({}): {:3.1f} ms'.format(device, t_pred*1e3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee90c1-ccee-419a-a060-306832f7fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: observe the results\n",
    "err = np.abs(series_future - prediction)\n",
    "rms_ini = np.sqrt(np.mean(series_future**2))\n",
    "rms = np.sqrt(np.mean(err**2))\n",
    "print(f'rms (initial): {rms_ini}')\n",
    "print(f'rms          : {rms}')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(forecast_window), series_future, label='true')\n",
    "for i in range(2):\n",
    "    plt.plot(predictions[i], label=f'prediction ({devices[i]})')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.abs(series_future - prediction))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d84610c-e444-4b46-aefb-8da273af8da7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Model ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46db318c-cd1d-4689-843a-d7e382155942",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_window = 300\n",
    "prediction_window = 150\n",
    "forecast_window = 100\n",
    "sequence_params = {\n",
    "    'training_window': training_window,\n",
    "    'prediction_window': prediction_window,\n",
    "    'step': 1\n",
    "}\n",
    "\n",
    "dataloader_params = {\n",
    "    'batch_size': 64,\n",
    "    'drop_last': False,\n",
    "}\n",
    "\n",
    "\n",
    "loaders = series_class.create_dataloaders(series_class.train_real,\n",
    "                                          series_class.train_imag,\n",
    "                                          series_class.test_real,\n",
    "                                          series_class.test_imag,\n",
    "                                          sequence_params,\n",
    "                                          dataloader_params)\n",
    "trainloader, testloader = loaders\n",
    "\n",
    "n_models = len(series_class.freq_filt)\n",
    "print(f'# of models: {n_models}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b08cfc-5c76-46d1-90de-c5b8449d909d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only two features now because every frequency band has its own model\n",
    "n_features = 2\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if use_cuda else 'cpu'\n",
    "print(device)\n",
    "\n",
    "n_hidden_fc = 152\n",
    "model_params = {\n",
    "    'n_features': n_features,\n",
    "    'n_hidden_lstm': 128,\n",
    "    'n_hidden_fc': n_hidden_fc,\n",
    "    'n_outputs': prediction_window*n_features,\n",
    "    'n_out_features': n_features,\n",
    "    'sequence_len': training_window,\n",
    "    'n_lstm_layers': 2,\n",
    "    'n_deep_layers': 1,\n",
    "    'dropout': 0.2,\n",
    "    'use_cuda': use_cuda\n",
    "}\n",
    "save_folder = f'models/rnn_stft_ensemble/'\n",
    "load_model = False\n",
    "\n",
    "model = None\n",
    "model_high_level = RNNSTFT_ensemble(model_params, model, save_folder, load_model,\n",
    "                                    n_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a70ccb9-cf74-4339-be3c-7c5b8ca1d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "n_epochs = 15\n",
    "\n",
    "# Initialize the loss function and optimizer\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = [torch.optim.AdamW(model_high_level.model[i].parameters(), lr=lr) for i in range(n_models)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc5a1ca-3ce7-4cd4-8426-bbd5058d2581",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = model_high_level.train(trainloader, testloader,\n",
    "                                criterion, optimizer, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2846b17-2ed9-4ca3-8458-7c1d2eddece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = np.array(losses[0])\n",
    "loss_test = np.array(losses[1])\n",
    "# print(loss)\n",
    "\n",
    "plt.figure(figsize=(20,20), layout='constrained')\n",
    "for i in range(min(n_models,49)):\n",
    "    plt.subplot(10,5,i+1)\n",
    "    plt.plot(loss_train[:,i], label='train')\n",
    "    plt.plot(loss_test[:,i], label='test')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.yscale('log')\n",
    "    plt.title('{:2.0f} Hz'.format(series_class.freq_filt[i]))\n",
    "    if i == 0:\n",
    "        plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53752f4d-a0f6-4ae2-ab2d-26336d08a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = 16000\n",
    "train = ts_data[:t0]\n",
    "test = ts_data[t0:]\n",
    "\n",
    "data, metrics = model_high_level.inference_on_dataloader(test, series_class,\n",
    "                                                         sequence_params,\n",
    "                                                         dataloader_params,\n",
    "                                                         forecast_window)\n",
    "predictions, actuals = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae161f04-58d1-420f-817f-97a2a4bcbf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shapes: {predictions.shape}, {actuals.shape}')\n",
    "print(f'MAE: {metrics[0]}')\n",
    "print(f'RMS: {metrics[1]}')\n",
    "\n",
    "# an example of prediction\n",
    "idx = 2000\n",
    "plt.figure()\n",
    "plt.plot(actuals[idx], label='true')\n",
    "plt.plot(predictions[idx], label='prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cffee0-ec2b-4a71-9d8a-5086c29e5c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare inference time for model on CPU/GPU\n",
    "# Step 1: create models on CPU/GPU\n",
    "models = []\n",
    "for use_cuda in [False, True]:\n",
    "    device = 'cuda' if use_cuda else 'cpu'\n",
    "    \n",
    "    model_params_local = model_params.copy()\n",
    "    model_params_local['use_cuda'] = use_cuda\n",
    "\n",
    "    model = None #LSTMForecaster(**model_params).to(device)\n",
    "    model_high_level = RNNSTFT_ensemble(model_params_local, model,\n",
    "                                        save_folder, load_model=True,\n",
    "                                        n_models=n_models)\n",
    "    models.append(model_high_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0dfafb-fa38-4e8d-bcee-aa77e1683ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: choose time-series slice\n",
    "t0 = 17500\n",
    "window_len = stft_params['noverlap']\n",
    "\n",
    "past_start, past_end = t0-window_len, t0+training_window \n",
    "future_start, future_end = t0+training_window, t0+training_window+forecast_window\n",
    "series_past = series_class.series[past_start:past_end].squeeze()\n",
    "series_future = series_class.series[future_start:future_end].squeeze()\n",
    "print(series_past.shape, series_future.shape)\n",
    "\n",
    "predictions = []\n",
    "devices = ['cpu', 'cuda']\n",
    "for i,device in enumerate(devices):\n",
    "    for j in range(models[i].n_models):\n",
    "        models[i].model[j].eval()\n",
    "    t_start = time.time()\n",
    "    prediction = models[i].predict_on_series(series_past, series_class, device=device)\n",
    "    prediction = prediction[-prediction_window:-prediction_window+forecast_window]\n",
    "    t_pred = time.time() - t_start\n",
    "    predictions.append(prediction)\n",
    "    print('Prediction time ({}): {:3.1f} ms'.format(device, t_pred*1e3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7269740f-1eba-45d9-b22f-3c3f7c7a2e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: observe the results\n",
    "err = np.abs(series_future - prediction)\n",
    "rms_ini = np.sqrt(np.mean(series_future**2))\n",
    "rms = np.sqrt(np.mean(err**2))\n",
    "print(f'rms (initial): {rms_ini}')\n",
    "print(f'rms          : {rms}')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(forecast_window), series_future, label='true')\n",
    "for i in range(2):\n",
    "    plt.plot(predictions[i], label=f'prediction ({devices[i]})')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.abs(series_future - prediction))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7beb843-6c60-4537-8254-8bd341ce8ace",
   "metadata": {},
   "source": [
    "## (Experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1846ed1-75af-4077-a28e-18dc1c829eee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
